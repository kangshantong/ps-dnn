[sparse_dict]
emb_dim=16

[net]
#fc,tanh,sigmoid,relu,softmax
layers=fc:64,relu:-1,fc:1,sigmoid:-1
model=fnn


[loss]
#cross_entropy,mse
loss=cross_entropy

[optimizer]
#adam,sgd,momentum,nesterov
optimizer=nesterov
learning_rate=0.001
#optimizer=adam
#learning_rate=0.00001

[train]
epoch=1
batch_size=1024

[test]
batch_size=8196

[debug]
interval=1000
